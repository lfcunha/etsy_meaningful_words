{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob as tb\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the most meaninful words of each of 10 Etsy stores, I chose the TF-IDF algorithm to score the importance of each word.\n",
    "TF-IDF (term frequence - inverse document frequency) scores words based on their frequency within a document, and their uniqueness to that document. Words that appear a lot in a document, but are rare in other documents, is very important to that document. While words that appear in a lot of other documents (such as \"the\", \"a\", \"what\") are less important.\n",
    "\n",
    "TF-IDF is widely used in search engines.\n",
    "\n",
    "\n",
    "The steps to identify the most meaningful words are:\n",
    " - obtain the data (text and description of each listing of each store)\n",
    " - concatenate all listings of each store\n",
    " - tokenize the text, remove stopwords, filter word types (such as removing adverbs), etc\n",
    " - perform tf-idf (I provide my own implementation, and a calculation using scikit-learn's implementation\n",
    " - extract the top n words by tf-idf score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_key = 'ggfgyosfeez1vnzek7h2ec68'\n",
    "stores_to_analyze = ['Plumailes','Leinloune','HalkaBOrganics','ArtsyBottleCapsUS','DesertSoulBabe','VintagePlanePrints','beachbohojewelryshop','SurplusHandsShop','Homewarebyleahmarie','AtHooksEnd']\n",
    "top_n_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req = r.get(\"https://s3.amazonaws.com/etsy-data/listings_text.json\")\n",
    "stores_listings = req.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all the listings of each store (both title and description), and store in a list of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_listings_and_preprocess_tokens():\n",
    "    \"\"\" Merge all store listings' text (title and description) and preprocess tokens by:\n",
    "        - lowercase\n",
    "        - remove newline character\n",
    "        - remove english stop words\n",
    "        - remove non-words (punctuation, digits)\n",
    "        - lemmatize to remove plurals\n",
    "        - remove words with one or two characters, to avoic abbreviations such as cm (centimeter)\n",
    "        - filter by word type (http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "            - remove adverbs, pronouns, interjections, etc.\n",
    "            - keep only Nouns, verbs, and adjectives, since these provide more meaningful descriptions of a store\n",
    "\n",
    "    Returns:\n",
    "        list(string): a list of strings. Each string is a filtered concatenation of all of the store's listings text\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    stopwords_dict = {k: None for v, k in enumerate(stopwords.words('english'))}\n",
    "    _bloblist = []  # list of text blob of all listings for each store\n",
    "    for store in stores_to_analyze:\n",
    "        store_text = \"\"\n",
    "        for listing in stores_listings[store]:\n",
    "            \n",
    "            store_text = store_text + \" \" + listing[\"title\"].replace(\"\\n\", \" \") + \" \" + \\\n",
    "                         listing[\"description\"].replace(\"\\n\", \" \")\n",
    "        store_text = store_text.split()  # tokenize, splitting on white space\n",
    "        filtered_words = [wnl.lemmatize(word.lower()) for word in store_text if\n",
    "                          len(word) > 2 and word.isalpha() and word not in stopwords_dict]\n",
    "        tagged = nltk.pos_tag(filtered_words)  # classify the type of the word\n",
    "        # word_tags = [x[1] for x in tagged]\n",
    "        # type_counter = Counter(word_tags)\n",
    "\n",
    "        filtered_words = [x[0] for x in tagged if\n",
    "                          x[1] in ('NN', 'NNS', 'JJ', 'JJS', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ')]\n",
    "\n",
    "        _bloblist += [\" \".join(filtered_words)]\n",
    "    return _bloblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textlist = merge_listings_and_preprocess_tokens()  # list of documents with concatenated listings text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate tf-idf scores using my own non-vectorized implementation of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    \"\"\" calculate term frequency with simple raw count. More advanced schemas could be used, such as binary, term frequency,\n",
    "        log normalization, double normalization 0.5, double normalization K.\n",
    "        See https://en.wikipedia.org/wiki/Tf%E2%80%93idf for more information\n",
    "\n",
    "    Args:\n",
    "        word (string):\n",
    "        blob (TextBlob):\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "\n",
    "def df(word, bloblist):\n",
    "    \"\"\"Calculate document frequency\n",
    "\n",
    "    Args:\n",
    "        word (string):\n",
    "        blob (TextBlob):\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    \"\"\"Calculate inverse document frequency\n",
    "\n",
    "    Args:\n",
    "        word (string):\n",
    "        blob (TextBlob):\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return math.log(len(bloblist) / (1 + df(word, bloblist)))\n",
    "\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        word (string): a single term\n",
    "        blob (TextBlob): a blob representation of the document text\n",
    "        bloblist (list): all documents\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bloblist = [tb(x) for x in textlist]  # convert each document to a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating tfidf scores of document 1 of 10\n",
      "\tStore: Plumailes. Top Words and tf-idf score:\n",
      "\t\tWord: earring, TF-IDF: 0.09316\n",
      "\t\tWord: hook, TF-IDF: 0.04467\n",
      "\t\tWord: unique, TF-IDF: 0.03296\n",
      "\t\tWord: rooster, TF-IDF: 0.02826\n",
      "\t\tWord: feather, TF-IDF: 0.02625\n",
      "Calculating tfidf scores of document 2 of 10\n",
      "\tStore: Leinloune. Top Words and tf-idf score:\n",
      "\t\tWord: album, TF-IDF: 0.03368\n",
      "\t\tWord: faux, TF-IDF: 0.02562\n",
      "\t\tWord: leinloune, TF-IDF: 0.02021\n",
      "\t\tWord: name, TF-IDF: 0.02016\n",
      "\t\tWord: cover, TF-IDF: 0.01848\n",
      "Calculating tfidf scores of document 3 of 10\n",
      "\tStore: HalkaBOrganics. Top Words and tf-idf score:\n",
      "\t\tWord: oil, TF-IDF: 0.08535\n",
      "\t\tWord: skin, TF-IDF: 0.02265\n",
      "\t\tWord: essential, TF-IDF: 0.01607\n",
      "\t\tWord: pure, TF-IDF: 0.01549\n",
      "\t\tWord: body, TF-IDF: 0.0132\n",
      "Calculating tfidf scores of document 4 of 10\n",
      "\tStore: ArtsyBottleCapsUS. Top Words and tf-idf score:\n",
      "\t\tWord: bottle, TF-IDF: 0.21601\n",
      "\t\tWord: cap, TF-IDF: 0.14674\n",
      "\t\tWord: epoxy, TF-IDF: 0.14201\n",
      "\t\tWord: military, TF-IDF: 0.13728\n",
      "\t\tWord: necklace, TF-IDF: 0.08354\n",
      "Calculating tfidf scores of document 5 of 10\n",
      "\tStore: DesertSoulBabe. Top Words and tf-idf score:\n",
      "\t\tWord: tank, TF-IDF: 0.05884\n",
      "\t\tWord: racerback, TF-IDF: 0.03647\n",
      "\t\tWord: llama, TF-IDF: 0.02569\n",
      "\t\tWord: combed, TF-IDF: 0.02486\n",
      "\t\tWord: sporty, TF-IDF: 0.01989\n",
      "Calculating tfidf scores of document 6 of 10\n",
      "\tStore: VintagePlanePrints. Top Words and tf-idf score:\n",
      "\t\tWord: file, TF-IDF: 0.09105\n",
      "\t\tWord: download, TF-IDF: 0.04869\n",
      "\t\tWord: digital, TF-IDF: 0.04158\n",
      "\t\tWord: print, TF-IDF: 0.04158\n",
      "\t\tWord: right, TF-IDF: 0.03677\n",
      "Calculating tfidf scores of document 7 of 10\n",
      "\tStore: beachbohojewelryshop. Top Words and tf-idf score:\n",
      "\t\tWord: necklace, TF-IDF: 0.06066\n",
      "\t\tWord: jewelry, TF-IDF: 0.05034\n",
      "\t\tWord: earring, TF-IDF: 0.04869\n",
      "\t\tWord: bracelet, TF-IDF: 0.02202\n",
      "\t\tWord: gold, TF-IDF: 0.01963\n",
      "Calculating tfidf scores of document 8 of 10\n",
      "\tStore: SurplusHandsShop. Top Words and tf-idf score:\n",
      "\t\tWord: website, TF-IDF: 0.04952\n",
      "\t\tWord: business, TF-IDF: 0.02767\n",
      "\t\tWord: content, TF-IDF: 0.02087\n",
      "\t\tWord: wordpress, TF-IDF: 0.01943\n",
      "\t\tWord: analytics, TF-IDF: 0.01598\n",
      "Calculating tfidf scores of document 9 of 10\n",
      "\tStore: Homewarebyleahmarie. Top Words and tf-idf score:\n",
      "\t\tWord: fabric, TF-IDF: 0.06262\n",
      "\t\tWord: hollowfibre, TF-IDF: 0.0626\n",
      "\t\tWord: bunting, TF-IDF: 0.05452\n",
      "\t\tWord: doorstop, TF-IDF: 0.05452\n",
      "\t\tWord: polycotton, TF-IDF: 0.05048\n",
      "Calculating tfidf scores of document 10 of 10\n",
      "\tStore: AtHooksEnd. Top Words and tf-idf score:\n",
      "\t\tWord: crocheted, TF-IDF: 0.23597\n",
      "\t\tWord: baby, TF-IDF: 0.03909\n",
      "\t\tWord: scarf, TF-IDF: 0.02942\n",
      "\t\tWord: decoration, TF-IDF: 0.02489\n",
      "\t\tWord: beanie, TF-IDF: 0.0242\n",
      "\n",
      "It took 31.47s to calculate tf-idf\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Calculating tfidf scores of document {} of {}\".format(i + 1, len(bloblist)))\n",
    "    print(\"\\tStore: {}. Top Words and tf-idf score:\".format(stores_to_analyze[i]))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:5]:\n",
    "        print(\"\\t\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "print(\"\\nIt took {}s to calculate tf-idf\".format(str(round(time()-start, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tf-idf scores using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words for Store Plumailes:\n",
      "      Word  tfidf score\n",
      "0  earring     0.191818\n",
      "1  feather     0.176312\n",
      "2   nickel     0.175881\n",
      "3  bouquet     0.172211\n",
      "4   unique     0.162860\n",
      "\n",
      "\n",
      "It took 0.03s to calculate tf-idf with scikit\n",
      "Top Words for Store Leinloune:\n",
      "           Word  tfidf score\n",
      "0          faux     0.149779\n",
      "1         cover     0.140206\n",
      "2  personalized     0.125894\n",
      "3          book     0.124788\n",
      "4          wire     0.122442\n",
      "\n",
      "\n",
      "It took 0.03s to calculate tf-idf with scikit\n",
      "Top Words for Store HalkaBOrganics:\n",
      "      Word  tfidf score\n",
      "0     skin     0.145128\n",
      "1     pure     0.135778\n",
      "2     seed     0.125515\n",
      "3     drop     0.121990\n",
      "4  organic     0.121511\n",
      "\n",
      "\n",
      "It took 0.03s to calculate tf-idf with scikit\n",
      "Top Words for Store ArtsyBottleCapsUS:\n",
      "        Word  tfidf score\n",
      "0     bottle     0.517588\n",
      "1   necklace     0.386179\n",
      "2        lot     0.383710\n",
      "3    support     0.382444\n",
      "4  available     0.232703\n",
      "\n",
      "\n",
      "It took 0.04s to calculate tf-idf with scikit\n",
      "Top Words for Store DesertSoulBabe:\n",
      "       Word  tfidf score\n",
      "0       mug     0.164597\n",
      "1  designed     0.151949\n",
      "2      good     0.145365\n",
      "3      cute     0.143884\n",
      "4      hope     0.139970\n",
      "\n",
      "\n",
      "It took 0.04s to calculate tf-idf with scikit\n",
      "Top Words for Store VintagePlanePrints:\n",
      "       Word  tfidf score\n",
      "0      file     0.246622\n",
      "1     right     0.212630\n",
      "2       zip     0.212278\n",
      "3     image     0.212278\n",
      "4  intended     0.212278\n",
      "\n",
      "\n",
      "It took 0.05s to calculate tf-idf with scikit\n",
      "Top Words for Store beachbohojewelryshop:\n",
      "       Word  tfidf score\n",
      "0   jewelry     0.201513\n",
      "1  necklace     0.186257\n",
      "2   earring     0.178575\n",
      "3  bracelet     0.167315\n",
      "4      bead     0.140565\n",
      "\n",
      "\n",
      "It took 0.05s to calculate tf-idf with scikit\n",
      "Top Words for Store SurplusHandsShop:\n",
      "       Word  tfidf score\n",
      "0  business     0.143977\n",
      "1   content     0.136940\n",
      "2   product     0.129480\n",
      "3     built     0.127920\n",
      "4      etsy     0.126257\n",
      "\n",
      "\n",
      "It took 0.05s to calculate tf-idf with scikit\n",
      "Top Words for Store Homewarebyleahmarie:\n",
      "      Word  tfidf score\n",
      "0     flag     0.261406\n",
      "1   fabric     0.260374\n",
      "2  measure     0.257565\n",
      "3  filling     0.257565\n",
      "4   shaped     0.253491\n",
      "\n",
      "\n",
      "It took 0.06s to calculate tf-idf with scikit\n",
      "Top Words for Store AtHooksEnd:\n",
      "         Word  tfidf score\n",
      "0       scarf     0.217739\n",
      "1  decoration     0.207536\n",
      "2        baby     0.197409\n",
      "3         age     0.195279\n",
      "4   christmas     0.187729\n",
      "\n",
      "\n",
      "It took 0.06s to calculate tf-idf with scikit\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "tokenize = lambda doc: doc.split(\" \")  # text was already pre-processed, otherwise it could be done here\n",
    "n_features = 1000  # n of words\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(norm='l2', min_df=2, max_df=0.95, use_idf=True, smooth_idf=False,\n",
    "                                   sublinear_tf=True, tokenizer=tokenize, max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(textlist)\n",
    "\n",
    "for i in range(len(textlist)):\n",
    "    top_n_words = top_n_words\n",
    "    row = np.squeeze(tfidf[i].toarray())\n",
    "    features = tfidf_vectorizer.get_feature_names()\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n_words]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['Word', 'tfidf score']\n",
    "    print(\"\"\"Top Words for Store {}:\"\"\".format(stores_to_analyze[i]))\n",
    "    print(df)\n",
    "    print()\n",
    "    print(\"\\nIt took {}s to calculate tf-idf with scikit\".format(str(round(time()-start, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used TF-IDF to score the relative importance of each word of each store. I implemented a naive version of\n",
    "the algorithms without any optimization (such as vectorization). The identified meaningful words mostly\n",
    "agree with the scoring performed by the implementation of scikit-learn library (with a few difference), which can be attributed to internal differences in the schema, \n",
    "such as for calculating the term frequency.\n",
    "\n",
    "The text was similarly pre-processed for both algorithms.  Tokenization involved:      \n",
    "        - lowercase\n",
    "        - remove newline character\n",
    "        - remove english stop words\n",
    "        - remove non-words (punctuation, digits)\n",
    "        - lemmatize to remove plurals\n",
    "        - remove words with one or two characters, to avoic abbreviations such as cm (centimeter)\n",
    "        - filter by word type (http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "            - remove adverbs, pronouns, interjections, etc.\n",
    "            - keep only Nouns, verbs, and adjectives, since these provide more meaningful descriptions of a store\n",
    "\n",
    "\n",
    "Finally, inspection of the webpage for each store (see urls below) reveals that the words found by the algorithm are reasonble in describing the respective store \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.etsy.com/shop/Plumailes/items\n",
    "https://www.etsy.com/shop/Leinloune/items\n",
    "https://www.etsy.com/shop/HalkaBOrganics/items\n",
    "https://www.etsy.com/shop/ArtsyBottleCapsUS/items\n",
    "https://www.etsy.com/shop/DesertSoulBabe/items\n",
    "https://www.etsy.com/shop/VintagePlanePrints/items\n",
    "https://www.etsy.com/shop/beachbohojewelryshop/items\n",
    "https://www.etsy.com/shop/SurplusHandsShop/items\n",
    "https://www.etsy.com/shop/Homewarebyleahmarie/items\n",
    "https://www.etsy.com/shop/AtHooksEnd/items\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}